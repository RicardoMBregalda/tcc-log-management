#!/usr/bin/env python3
"""
Testes de Toler√¢ncia a Falhas - TCC Log Management

Compara√ß√£o abrangente entre arquiteturas H√≠brida (Fabric) e Tradicional (PostgreSQL)
focando em:
- Tempo de recupera√ß√£o (Recovery Time Objective - RTO)
- Integridade dos dados (Recovery Point Objective - RPO)
- Comportamento durante falhas
- Consist√™ncia ap√≥s recupera√ß√£o

Cen√°rios de Falha:
1. Queda do banco de dados principal
2. Queda de n√≥ de replica√ß√£o
3. Falha de rede tempor√°ria
4. Falha durante escrita
5. M√∫ltiplas falhas simult√¢neas

Autor: Ricardo M Bregalda
Data: 2025-10-16
"""

import sys
import time
import json
import subprocess
import requests
import psycopg2
import threading
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict, field
from collections import defaultdict

# MongoDB
try:
    from pymongo import MongoClient
    MONGO_AVAILABLE = True
except ImportError:
    MONGO_AVAILABLE = False
    print("‚ö†Ô∏è  Warning: pymongo not installed. MongoDB tests will be limited.")

# Adiciona diret√≥rio pai ao path
sys.path.append(str(Path(__file__).parent.parent))

from config import (
    API_BASE_URL,
    API_TIMEOUT,
    POSTGRES_HOST,
    POSTGRES_PORT,
    POSTGRES_DB,
    POSTGRES_USER,
    POSTGRES_PASSWORD,
    MONGO_URL,
    MONGO_DB,
    MONGO_COLLECTION,
)


# ==================== CONFIGURA√á√ÉO ====================

RESULTS_DIR = Path(__file__).parent.parent / "results"
RESULTS_DIR.mkdir(exist_ok=True)

# Containers Docker
CONTAINERS = {
    # Arquitetura H√≠brida
    'mongo': 'mongo',
    'peer0': 'peer0.org1.example.com',
    'peer1': 'peer1.org1.example.com',
    'peer2': 'peer2.org1.example.com',
    'orderer': 'orderer.example.com',
    
    # Arquitetura Tradicional
    'postgres_primary': 'postgres-primary',
    'postgres_standby': 'postgres-standby',
}

# Configura√ß√£o dos testes
CONFIG = {
    'logs_per_second': 10,
    'test_duration': 30,  # segundos
    'failure_at': 10,  # injetar falha ap√≥s 10s
    'recovery_timeout': 60,  # timeout para recupera√ß√£o
    'verification_samples': 100,  # amostras para verificar integridade
}


# ==================== DATACLASSES ====================

@dataclass
class FailureMetrics:
    """M√©tricas de uma falha espec√≠fica"""
    # Identifica√ß√£o
    scenario: str
    architecture: str
    component: str
    
    # Timeline
    test_start: datetime
    failure_injected: datetime
    failure_detected: Optional[datetime] = None
    recovery_started: Optional[datetime] = None
    recovery_completed: Optional[datetime] = None
    test_end: Optional[datetime] = None
    
    # Tempos (em segundos)
    detection_time: Optional[float] = None
    recovery_time: Optional[float] = None
    total_downtime: Optional[float] = None
    
    # Integridade de dados
    logs_before_failure: int = 0
    logs_during_failure: int = 0
    logs_after_recovery: int = 0
    logs_sent_total: int = 0
    logs_received_total: int = 0
    logs_lost: int = 0
    loss_percentage: float = 0.0
    
    # Comportamento
    continued_operating: bool = False
    automatic_recovery: bool = False
    data_consistent: bool = False
    
    # Detalhes
    error_messages: List[str] = field(default_factory=list)
    notes: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict:
        """Converte para dicion√°rio com campos formatados"""
        return {
            'scenario': self.scenario,
            'architecture': self.architecture,
            'component': self.component,
            'test_start': self.test_start.isoformat() if self.test_start else None,
            'failure_injected': self.failure_injected.isoformat() if self.failure_injected else None,
            'failure_detected': self.failure_detected.isoformat() if self.failure_detected else None,
            'recovery_started': self.recovery_started.isoformat() if self.recovery_started else None,
            'recovery_completed': self.recovery_completed.isoformat() if self.recovery_completed else None,
            'test_end': self.test_end.isoformat() if self.test_end else None,
            'detection_time': round(self.detection_time, 2) if self.detection_time else None,
            'recovery_time': round(self.recovery_time, 2) if self.recovery_time else None,
            'total_downtime': round(self.total_downtime, 2) if self.total_downtime else None,
            'logs_before_failure': self.logs_before_failure,
            'logs_during_failure': self.logs_during_failure,
            'logs_after_recovery': self.logs_after_recovery,
            'logs_sent_total': self.logs_sent_total,
            'logs_received_total': self.logs_received_total,
            'logs_lost': self.logs_lost,
            'loss_percentage': round(self.loss_percentage, 2),
            'continued_operating': self.continued_operating,
            'automatic_recovery': self.automatic_recovery,
            'data_consistent': self.data_consistent,
            'error_messages': self.error_messages,
            'notes': self.notes,
        }


@dataclass
class ComparisonResult:
    """Resultado da compara√ß√£o entre arquiteturas"""
    scenario: str
    hybrid: FailureMetrics
    traditional: FailureMetrics
    
    # Vencedores por m√©trica
    faster_detection: str  # 'hybrid', 'traditional', 'tie'
    faster_recovery: str
    less_data_loss: str
    better_availability: str
    
    # Diferen√ßas
    detection_time_diff: float
    recovery_time_diff: float
    data_loss_diff: float
    
    summary: str


# ==================== CLASSE PRINCIPAL ====================

class FaultToleranceTest:
    """Gerenciador de testes de toler√¢ncia a falhas"""
    
    def __init__(self):
        self.metrics: List[FailureMetrics] = []
        self.log_ids: List[str] = []  # IDs dos logs enviados
        self.stop_flag = False
        
    # ==================== DOCKER UTILS ====================
    
    def docker_stop(self, container: str) -> Tuple[bool, str]:
        """Para um container Docker"""
        print(f"    üî¥ Parando container: {container}")
        try:
            result = subprocess.run(
                ['docker', 'stop', container],
                capture_output=True,
                text=True,
                timeout=15
            )
            return result.returncode == 0, result.stdout or result.stderr
        except Exception as e:
            return False, str(e)
    
    def docker_start(self, container: str) -> Tuple[bool, str]:
        """Inicia um container Docker"""
        print(f"    üü¢ Iniciando container: {container}")
        try:
            result = subprocess.run(
                ['docker', 'start', container],
                capture_output=True,
                text=True,
                timeout=15
            )
            return result.returncode == 0, result.stdout or result.stderr
        except Exception as e:
            return False, str(e)
    
    def docker_is_running(self, container: str) -> bool:
        """Verifica se container est√° rodando"""
        try:
            result = subprocess.run(
                ['docker', 'ps', '--filter', f'name=^{container}$', '--format', '{{.Names}}'],
                capture_output=True,
                text=True,
                timeout=5
            )
            return container in result.stdout.strip()
        except:
            return False
    
    def docker_pause(self, container: str) -> Tuple[bool, str]:
        """Pausa um container (simula falha de rede)"""
        print(f"    ‚è∏Ô∏è  Pausando container: {container}")
        try:
            result = subprocess.run(
                ['docker', 'pause', container],
                capture_output=True,
                text=True,
                timeout=10
            )
            return result.returncode == 0, result.stdout or result.stderr
        except Exception as e:
            return False, str(e)
    
    def docker_unpause(self, container: str) -> Tuple[bool, str]:
        """Despausa um container"""
        print(f"    ‚ñ∂Ô∏è  Despausando container: {container}")
        try:
            result = subprocess.run(
                ['docker', 'unpause', container],
                capture_output=True,
                text=True,
                timeout=10
            )
            return result.returncode == 0, result.stdout or result.stderr
        except Exception as e:
            return False, str(e)
    
    # ==================== POSTGRESQL UTILS ====================
    
    def postgres_connect(self, host: str = POSTGRES_HOST, port: int = POSTGRES_PORT) -> Optional[psycopg2.extensions.connection]:
        """Conecta ao PostgreSQL"""
        try:
            conn = psycopg2.connect(
                host=host,
                port=port,
                database=POSTGRES_DB,
                user=POSTGRES_USER,
                password=POSTGRES_PASSWORD,
                connect_timeout=5
            )
            return conn
        except Exception as e:
            return None
    
    def postgres_insert_log(self, conn, log_id: str, message: str) -> bool:
        """Insere log no PostgreSQL"""
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO logs (id, timestamp, source, level, message, metadata)
                    VALUES (%s, NOW(), %s, %s, %s, %s)
                """, (log_id, 'fault-tolerance-test', 'INFO', message, '{}'))
                conn.commit()
            return True
        except Exception as e:
            return False
    
    def postgres_count_logs(self, conn, source: str = 'fault-tolerance-test') -> int:
        """Conta logs no PostgreSQL"""
        try:
            with conn.cursor() as cur:
                cur.execute("SELECT COUNT(*) FROM logs WHERE source = %s", (source,))
                return cur.fetchone()[0]
        except:
            return -1
    
    def postgres_verify_log(self, conn, log_id: str) -> bool:
        """Verifica se log existe no PostgreSQL"""
        try:
            with conn.cursor() as cur:
                cur.execute("SELECT 1 FROM logs WHERE id = %s", (log_id,))
                return cur.fetchone() is not None
        except:
            return False
    
    def postgres_is_primary(self, host: str = POSTGRES_HOST, port: int = POSTGRES_PORT) -> Optional[bool]:
        """Verifica se inst√¢ncia √© primary (n√£o est√° em recovery)"""
        conn = self.postgres_connect(host, port)
        if not conn:
            return None
        
        try:
            with conn.cursor() as cur:
                cur.execute("SELECT pg_is_in_recovery()")
                in_recovery = cur.fetchone()[0]
                conn.close()
                return not in_recovery
        except:
            if conn:
                conn.close()
            return None
    
    # ==================== HYBRID API UTILS ====================
    
    def api_insert_log(self, log_id: str, message: str) -> Tuple[bool, Optional[str]]:
        """Insere log via API h√≠brida"""
        try:
            response = requests.post(
                f"{API_BASE_URL}/logs",
                json={
                    'id': log_id,
                    'timestamp': datetime.now().isoformat(),
                    'source': 'fault-tolerance-test',
                    'level': 'INFO',
                    'message': message,
                    'metadata': {}
                },
                timeout=5
            )
            
            if response.status_code in [200, 201]:
                return True, None
            else:
                return False, f"HTTP {response.status_code}: {response.text}"
        except requests.exceptions.RequestException as e:
            return False, str(e)
    
    def api_get_log(self, log_id: str) -> Tuple[bool, Optional[Dict]]:
        """Busca log via API h√≠brida"""
        try:
            response = requests.get(
                f"{API_BASE_URL}/logs/{log_id}",
                timeout=5
            )
            
            if response.status_code == 200:
                return True, response.json()
            else:
                return False, None
        except:
            return False, None
    
    def api_health_check(self) -> bool:
        """Verifica sa√∫de da API"""
        try:
            response = requests.get(f"{API_BASE_URL}/health", timeout=3)
            return response.status_code == 200
        except:
            return False
    
    # ==================== MONGODB UTILS ====================
    
    def mongo_connect(self) -> Optional[MongoClient]:
        """Conecta ao MongoDB"""
        if not MONGO_AVAILABLE:
            return None
        try:
            client = MongoClient(MONGO_URL, serverSelectionTimeoutMS=5000)
            # Testa conex√£o
            client.admin.command('ping')
            return client
        except Exception as e:
            return None
    
    def mongo_insert_log(self, client: MongoClient, log_id: str, message: str) -> bool:
        """Insere log diretamente no MongoDB"""
        try:
            db = client[MONGO_DB]
            collection = db[MONGO_COLLECTION]
            
            log_doc = {
                'id': log_id,
                'timestamp': datetime.now().isoformat(),
                'source': 'fault-tolerance-test',
                'level': 'INFO',
                'message': message,
                'metadata': {},
                'created_at': datetime.utcnow()
            }
            
            collection.insert_one(log_doc)
            return True
        except Exception as e:
            return False
    
    def mongo_count_logs(self, client: MongoClient, source: str = 'fault-tolerance-test') -> int:
        """Conta logs no MongoDB"""
        try:
            db = client[MONGO_DB]
            collection = db[MONGO_COLLECTION]
            return collection.count_documents({'source': source})
        except:
            return -1
    
    def mongo_verify_log(self, client: MongoClient, log_id: str) -> bool:
        """Verifica se log existe no MongoDB"""
        try:
            db = client[MONGO_DB]
            collection = db[MONGO_COLLECTION]
            return collection.find_one({'id': log_id}) is not None
        except:
            return False
    
    def mongo_clear_test_logs(self, client: MongoClient):
        """Limpa logs de teste do MongoDB"""
        try:
            db = client[MONGO_DB]
            collection = db[MONGO_COLLECTION]
            collection.delete_many({'source': 'fault-tolerance-test'})
        except:
            pass
    
    # ==================== CEN√ÅRIOS DE TESTE ====================
    
    def test_scenario_1_primary_failure(self, architecture: str) -> FailureMetrics:
        """
        CEN√ÅRIO 1: Queda do banco de dados principal
        
        PostgreSQL: Primary cai, standby deve assumir (promo√ß√£o manual necess√°ria)
        Hybrid: MongoDB cai, sistema deve falhar (sem replica√ß√£o configurada)
        """
        print(f"\n{'='*70}")
        print(f"  CEN√ÅRIO 1: Falha do Banco de Dados Principal")
        print(f"  Arquitetura: {architecture.upper()}")
        print(f"{'='*70}")
        
        metrics = FailureMetrics(
            scenario='primary_database_failure',
            architecture=architecture,
            component='postgres-primary' if architecture == 'traditional' else 'mongo',
            test_start=datetime.now(),
            failure_injected=datetime.now()
        )
        
        self.log_ids = []
        logs_sent = {'before': 0, 'during': 0, 'after': 0}
        
        try:
            # FASE 1: Opera√ß√£o normal (10 segundos)
            print("\n  üìä FASE 1: Opera√ß√£o Normal (10s)")
            print("  " + "-" * 66)
            
            phase_start = time.time()
            while time.time() - phase_start < 10:
                log_id = f"ft-s1-{architecture}-{int(time.time()*1000)}"
                self.log_ids.append(log_id)
                
                if architecture == 'traditional':
                    conn = self.postgres_connect()
                    if conn:
                        success = self.postgres_insert_log(conn, log_id, f"Log antes da falha #{logs_sent['before']}")
                        conn.close()
                        if success:
                            logs_sent['before'] += 1
                else:
                    success, _ = self.api_insert_log(log_id, f"Log antes da falha #{logs_sent['before']}")
                    if success:
                        logs_sent['before'] += 1
                
                time.sleep(0.1)
            
            metrics.logs_before_failure = logs_sent['before']
            print(f"  ‚úÖ Logs enviados na FASE 1: {logs_sent['before']}")
            
            # FASE 2: Injetar falha
            print(f"\n  üí• FASE 2: Injetando Falha")
            print("  " + "-" * 66)
            
            metrics.failure_injected = datetime.now()
            container = CONTAINERS['postgres_primary'] if architecture == 'traditional' else CONTAINERS['mongo']
            
            success, msg = self.docker_stop(container)
            if not success:
                metrics.notes.append(f"Falha ao parar container: {msg}")
                raise Exception(f"Erro ao parar container: {msg}")
            
            print(f"  ‚úÖ Container parado: {container}")
            
            # FASE 3: Opera√ß√£o durante falha (10 segundos)
            print(f"\n  üìä FASE 3: Opera√ß√£o Durante Falha (10s)")
            print("  " + "-" * 66)
            
            metrics.failure_detected = datetime.now()
            metrics.detection_time = (metrics.failure_detected - metrics.failure_injected).total_seconds()
            
            phase_start = time.time()
            first_error = None
            
            while time.time() - phase_start < 10:
                log_id = f"ft-s1-{architecture}-{int(time.time()*1000)}"
                self.log_ids.append(log_id)
                
                if architecture == 'traditional':
                    conn = self.postgres_connect()
                    if conn:
                        success = self.postgres_insert_log(conn, log_id, f"Log durante falha #{logs_sent['during']}")
                        conn.close()
                        if success:
                            logs_sent['during'] += 1
                            metrics.continued_operating = True
                    else:
                        if first_error is None:
                            first_error = "Conex√£o recusada"
                else:
                    success, error = self.api_insert_log(log_id, f"Log durante falha #{logs_sent['during']}")
                    if success:
                        logs_sent['during'] += 1
                        metrics.continued_operating = True
                    elif first_error is None:
                        first_error = error
                
                time.sleep(0.1)
            
            metrics.logs_during_failure = logs_sent['during']
            print(f"  üìä Logs enviados na FASE 3: {logs_sent['during']}")
            
            if first_error:
                metrics.error_messages.append(first_error)
                print(f"  ‚ö†Ô∏è  Primeiro erro detectado: {first_error[:80]}")
            
            # FASE 4: Recupera√ß√£o
            print(f"\n  üîÑ FASE 4: Recupera√ß√£o")
            print("  " + "-" * 66)
            
            metrics.recovery_started = datetime.now()
            
            # Reiniciar container
            success, msg = self.docker_start(container)
            if not success:
                raise Exception(f"Erro ao iniciar container: {msg}")
            
            print(f"  ‚è≥ Aguardando container ficar dispon√≠vel...")
            
            # Para arquitetura h√≠brida, reiniciar API ap√≥s MongoDB voltar
            if architecture == 'hybrid':
                print(f"  üîÑ Reiniciando API para reconectar ao MongoDB...")
                
                # Usar script bash para reiniciar API (mais confi√°vel)
                try:
                    result = subprocess.run(
                        ['bash', '/root/tcc-log-management/testing/scripts/start_api.sh'],
                        capture_output=True,
                        text=True,
                        timeout=15
                    )
                    if result.returncode == 0:
                        print(f"  ‚úÖ API reiniciada com sucesso")
                    else:
                        print(f"  ‚ö†Ô∏è  API pode n√£o ter iniciado corretamente")
                except Exception as e:
                    print(f"  ‚ö†Ô∏è  Erro ao reiniciar API: {e}")
                
                time.sleep(2)  # Tempo adicional de estabiliza√ß√£o
            
            # Aguardar recupera√ß√£o
            recovery_timeout = 60
            recovery_start = time.time()
            recovered = False
            
            while time.time() - recovery_start < recovery_timeout:
                if architecture == 'traditional':
                    conn = self.postgres_connect()
                    if conn:
                        conn.close()
                        recovered = True
                        break
                else:
                    if self.api_health_check():
                        recovered = True
                        break
                
                time.sleep(1)
            
            if recovered:
                metrics.recovery_completed = datetime.now()
                metrics.recovery_time = (metrics.recovery_completed - metrics.recovery_started).total_seconds()
                metrics.automatic_recovery = True
                print(f"  ‚úÖ Sistema recuperado em {metrics.recovery_time:.2f}s")
            else:
                metrics.notes.append("Timeout de recupera√ß√£o excedido")
                print(f"  ‚ùå Timeout de recupera√ß√£o ({recovery_timeout}s)")
            
            # FASE 5: Verifica√ß√£o p√≥s-recupera√ß√£o (10 segundos)
            print(f"\n  üìä FASE 5: Verifica√ß√£o P√≥s-Recupera√ß√£o (10s)")
            print("  " + "-" * 66)
            
            if recovered:
                phase_start = time.time()
                while time.time() - phase_start < 10:
                    log_id = f"ft-s1-{architecture}-{int(time.time()*1000)}"
                    self.log_ids.append(log_id)
                    
                    if architecture == 'traditional':
                        conn = self.postgres_connect()
                        if conn:
                            success = self.postgres_insert_log(conn, log_id, f"Log p√≥s-recupera√ß√£o #{logs_sent['after']}")
                            conn.close()
                            if success:
                                logs_sent['after'] += 1
                    else:
                        success, _ = self.api_insert_log(log_id, f"Log p√≥s-recupera√ß√£o #{logs_sent['after']}")
                        if success:
                            logs_sent['after'] += 1
                    
                    time.sleep(0.1)
            
            metrics.logs_after_recovery = logs_sent['after']
            print(f"  ‚úÖ Logs enviados na FASE 5: {logs_sent['after']}")
            
            # FASE 6: Verifica√ß√£o de integridade
            print(f"\n  üîç FASE 6: Verifica√ß√£o de Integridade")
            print("  " + "-" * 66)
            
            metrics.logs_sent_total = len(self.log_ids)
            logs_received = 0
            
            # Verificar amostra de logs
            sample_size = min(100, len(self.log_ids))
            sample_ids = self.log_ids[::max(1, len(self.log_ids) // sample_size)]
            
            print(f"  üìä Verificando {len(sample_ids)} logs de amostra...")
            
            if architecture == 'traditional':
                # PostgreSQL: Conecta diretamente ao banco
                conn = self.postgres_connect()
                if conn:
                    for log_id in sample_ids:
                        if self.postgres_verify_log(conn, log_id):
                            logs_received += 1
                    conn.close()
            else:
                # H√≠brida: Conecta diretamente ao MongoDB (n√£o via API)
                # Isso garante que verificamos o que realmente foi persistido
                mongo_client = self.mongo_connect()
                if mongo_client:
                    for log_id in sample_ids:
                        if self.mongo_verify_log(mongo_client, log_id):
                            logs_received += 1
                    mongo_client.close()
                else:
                    # Fallback para API se MongoDB n√£o estiver dispon√≠vel
                    print(f"  ‚ö†Ô∏è  MongoDB n√£o dispon√≠vel, tentando via API...")
                    for log_id in sample_ids:
                        success, _ = self.api_get_log(log_id)
                        if success:
                            logs_received += 1
            
            # Extrapolar para total
            if len(sample_ids) > 0:
                metrics.logs_received_total = int((logs_received / len(sample_ids)) * metrics.logs_sent_total)
            else:
                metrics.logs_received_total = 0
            
            metrics.logs_lost = metrics.logs_sent_total - metrics.logs_received_total
            metrics.loss_percentage = (metrics.logs_lost / metrics.logs_sent_total * 100) if metrics.logs_sent_total > 0 else 0
            metrics.data_consistent = metrics.logs_lost == 0
            
            print(f"  üìä Amostra verificada: {logs_received}/{len(sample_ids)}")
            print(f"  üìä Logs enviados: {metrics.logs_sent_total}")
            print(f"  üìä Logs recebidos: {metrics.logs_received_total}")
            print(f"  üìä Logs perdidos: {metrics.logs_lost} ({metrics.loss_percentage:.2f}%)")
            print(f"  {'‚úÖ' if metrics.data_consistent else '‚ö†Ô∏è '} Integridade: {'OK' if metrics.data_consistent else 'FALHA'}")
            
        except Exception as e:
            metrics.notes.append(f"Erro durante teste: {str(e)}")
            print(f"\n  ‚ùå ERRO: {str(e)}")
        
        finally:
            metrics.test_end = datetime.now()
            if metrics.failure_detected and metrics.recovery_completed:
                metrics.total_downtime = (metrics.recovery_completed - metrics.failure_detected).total_seconds()
        
        return metrics
    
    def test_scenario_2_standby_failure(self, architecture: str) -> FailureMetrics:
        """
        CEN√ÅRIO 2: Queda do n√≥ de replica√ß√£o
        
        PostgreSQL: Standby cai, primary continua operando
        Hybrid: Peer secund√°rio cai, rede Fabric continua
        """
        print(f"\n{'='*70}")
        print(f"  CEN√ÅRIO 2: Falha do N√≥ de Replica√ß√£o")
        print(f"  Arquitetura: {architecture.upper()}")
        print(f"{'='*70}")
        
        metrics = FailureMetrics(
            scenario='replica_node_failure',
            architecture=architecture,
            component='postgres-standby' if architecture == 'traditional' else 'peer1',
            test_start=datetime.now(),
            failure_injected=datetime.now()
        )
        
        self.log_ids = []
        logs_sent = {'before': 0, 'during': 0, 'after': 0}
        
        try:
            # FASE 1: Opera√ß√£o normal
            print("\n  üìä FASE 1: Opera√ß√£o Normal (5s)")
            print("  " + "-" * 66)
            
            phase_start = time.time()
            while time.time() - phase_start < 5:
                log_id = f"ft-s2-{architecture}-{int(time.time()*1000)}"
                self.log_ids.append(log_id)
                
                if architecture == 'traditional':
                    conn = self.postgres_connect()
                    if conn:
                        if self.postgres_insert_log(conn, log_id, f"Log antes #{logs_sent['before']}"):
                            logs_sent['before'] += 1
                        conn.close()
                else:
                    if self.api_insert_log(log_id, f"Log antes #{logs_sent['before']}")[0]:
                        logs_sent['before'] += 1
                
                time.sleep(0.1)
            
            metrics.logs_before_failure = logs_sent['before']
            print(f"  ‚úÖ Logs enviados: {logs_sent['before']}")
            
            # FASE 2: Injetar falha
            print(f"\n  üí• FASE 2: Injetando Falha no N√≥ Secund√°rio")
            print("  " + "-" * 66)
            
            metrics.failure_injected = datetime.now()
            container = CONTAINERS['postgres_standby'] if architecture == 'traditional' else CONTAINERS['peer1']
            
            self.docker_stop(container)
            print(f"  ‚úÖ Container parado: {container}")
            
            # FASE 3: Opera√ß√£o ap√≥s falha (primary deve continuar)
            print(f"\n  üìä FASE 3: Opera√ß√£o com R√©plica Indispon√≠vel (10s)")
            print("  " + "-" * 66)
            
            metrics.failure_detected = datetime.now()
            metrics.detection_time = (metrics.failure_detected - metrics.failure_injected).total_seconds()
            
            phase_start = time.time()
            while time.time() - phase_start < 10:
                log_id = f"ft-s2-{architecture}-{int(time.time()*1000)}"
                self.log_ids.append(log_id)
                
                if architecture == 'traditional':
                    conn = self.postgres_connect()
                    if conn:
                        if self.postgres_insert_log(conn, log_id, f"Log durante #{logs_sent['during']}"):
                            logs_sent['during'] += 1
                            metrics.continued_operating = True
                        conn.close()
                else:
                    if self.api_insert_log(log_id, f"Log durante #{logs_sent['during']}")[0]:
                        logs_sent['during'] += 1
                        metrics.continued_operating = True
                
                time.sleep(0.1)
            
            metrics.logs_during_failure = logs_sent['during']
            print(f"  ‚úÖ Logs enviados durante falha: {logs_sent['during']}")
            print(f"  {'‚úÖ' if metrics.continued_operating else '‚ùå'} Sistema continuou operando")
            
            # FASE 4: Recuperar r√©plica
            print(f"\n  üîÑ FASE 4: Recuperando R√©plica")
            print("  " + "-" * 66)
            
            metrics.recovery_started = datetime.now()
            self.docker_start(container)
            
            # Aguardar recupera√ß√£o
            time.sleep(15)  # Tempo para standby se conectar
            
            metrics.recovery_completed = datetime.now()
            metrics.recovery_time = (metrics.recovery_completed - metrics.recovery_started).total_seconds()
            metrics.automatic_recovery = True
            
            print(f"  ‚úÖ R√©plica recuperada em {metrics.recovery_time:.2f}s")
            
            # FASE 5: Verificar sincroniza√ß√£o
            print(f"\n  üîç FASE 5: Verificando Sincroniza√ß√£o")
            print("  " + "-" * 66)
            
            if architecture == 'traditional':
                # Verificar replica√ß√£o
                time.sleep(5)  # Aguardar replica√ß√£o alcan√ßar
                
                # Verificar se standby est√° em recovery e replicando
                standby_ok = self.postgres_is_primary(POSTGRES_HOST, 5433) == False
                
                if standby_ok:
                    metrics.data_consistent = True
                    print(f"  ‚úÖ Standby sincronizado e replicando")
                else:
                    print(f"  ‚ö†Ô∏è  Standby n√£o sincronizou completamente")
            
            metrics.logs_sent_total = len(self.log_ids)
            metrics.logs_received_total = logs_sent['before'] + logs_sent['during']
            metrics.logs_lost = 0
            metrics.loss_percentage = 0.0
            
        except Exception as e:
            metrics.notes.append(f"Erro: {str(e)}")
            print(f"\n  ‚ùå ERRO: {str(e)}")
        
        finally:
            metrics.test_end = datetime.now()
            if metrics.failure_detected and metrics.recovery_completed:
                metrics.total_downtime = 0  # Sem downtime para o primary
        
        return metrics
    
    def test_scenario_3_network_partition(self, architecture: str) -> FailureMetrics:
        """
        CEN√ÅRIO 3: Falha de rede tempor√°ria (simula com docker pause)
        
        PostgreSQL: Primary pausado, simula perda de rede
        Hybrid: MongoDB pausado
        """
        print(f"\n{'='*70}")
        print(f"  CEN√ÅRIO 3: Falha de Rede Tempor√°ria")
        print(f"  Arquitetura: {architecture.upper()}")
        print(f"{'='*70}")
        
        metrics = FailureMetrics(
            scenario='network_partition',
            architecture=architecture,
            component='postgres-primary' if architecture == 'traditional' else 'mongo',
            test_start=datetime.now(),
            failure_injected=datetime.now()
        )
        
        self.log_ids = []
        logs_sent = {'before': 0, 'during': 0, 'after': 0}
        
        try:
            # FASE 1: Opera√ß√£o normal
            print("\n  üìä FASE 1: Opera√ß√£o Normal (5s)")
            phase_start = time.time()
            while time.time() - phase_start < 5:
                log_id = f"ft-s3-{architecture}-{int(time.time()*1000)}"
                self.log_ids.append(log_id)
                
                if architecture == 'traditional':
                    conn = self.postgres_connect()
                    if conn:
                        if self.postgres_insert_log(conn, log_id, f"Log #{logs_sent['before']}"):
                            logs_sent['before'] += 1
                        conn.close()
                else:
                    if self.api_insert_log(log_id, f"Log #{logs_sent['before']}")[0]:
                        logs_sent['before'] += 1
                
                time.sleep(0.1)
            
            metrics.logs_before_failure = logs_sent['before']
            print(f"  ‚úÖ Logs enviados: {logs_sent['before']}")
            
            # FASE 2: Pausar container (simula perda de rede)
            print(f"\n  üí• FASE 2: Simulando Perda de Rede (docker pause)")
            
            metrics.failure_injected = datetime.now()
            container = CONTAINERS['postgres_primary'] if architecture == 'traditional' else CONTAINERS['mongo']
            
            self.docker_pause(container)
            print(f"  ‚è∏Ô∏è  Container pausado: {container}")
            
            # FASE 3: Tentar opera√ß√µes (devem falhar)
            print(f"\n  üìä FASE 3: Tentando Opera√ß√µes Durante Perda de Rede (10s)")
            
            metrics.failure_detected = datetime.now()
            phase_start = time.time()
            
            while time.time() - phase_start < 10:
                log_id = f"ft-s3-{architecture}-{int(time.time()*1000)}"
                self.log_ids.append(log_id)
                
                if architecture == 'traditional':
                    conn = self.postgres_connect()
                    if conn:
                        if self.postgres_insert_log(conn, log_id, f"Log #{logs_sent['during']}"):
                            logs_sent['during'] += 1
                        conn.close()
                else:
                    if self.api_insert_log(log_id, f"Log #{logs_sent['during']}")[0]:
                        logs_sent['during'] += 1
                
                time.sleep(0.1)
            
            metrics.logs_during_failure = logs_sent['during']
            print(f"  üìä Logs enviados durante falha: {logs_sent['during']}")
            
            # FASE 4: Restaurar rede
            print(f"\n  üîÑ FASE 4: Restaurando Rede")
            
            metrics.recovery_started = datetime.now()
            self.docker_unpause(container)
            print(f"  ‚ñ∂Ô∏è  Container despausado")
            
            # Aguardar recupera√ß√£o
            time.sleep(5)
            
            metrics.recovery_completed = datetime.now()
            metrics.recovery_time = (metrics.recovery_completed - metrics.recovery_started).total_seconds()
            metrics.automatic_recovery = True
            
            # FASE 5: Verificar recupera√ß√£o
            print(f"\n  üìä FASE 5: Verificando Recupera√ß√£o (5s)")
            
            phase_start = time.time()
            while time.time() - phase_start < 5:
                log_id = f"ft-s3-{architecture}-{int(time.time()*1000)}"
                self.log_ids.append(log_id)
                
                if architecture == 'traditional':
                    conn = self.postgres_connect()
                    if conn:
                        if self.postgres_insert_log(conn, log_id, f"Log p√≥s #{logs_sent['after']}"):
                            logs_sent['after'] += 1
                            metrics.continued_operating = True
                        conn.close()
                else:
                    if self.api_insert_log(log_id, f"Log p√≥s #{logs_sent['after']}")[0]:
                        logs_sent['after'] += 1
                        metrics.continued_operating = True
                
                time.sleep(0.1)
            
            metrics.logs_after_recovery = logs_sent['after']
            print(f"  ‚úÖ Logs enviados ap√≥s recupera√ß√£o: {logs_sent['after']}")
            
            metrics.logs_sent_total = len(self.log_ids)
            metrics.logs_received_total = logs_sent['before'] + logs_sent['after']
            metrics.logs_lost = logs_sent['during']
            metrics.loss_percentage = (metrics.logs_lost / metrics.logs_sent_total * 100) if metrics.logs_sent_total > 0 else 0
            
            print(f"  üìä Perda de dados: {metrics.logs_lost} logs ({metrics.loss_percentage:.2f}%)")
            
        except Exception as e:
            metrics.notes.append(f"Erro: {str(e)}")
            print(f"\n  ‚ùå ERRO: {str(e)}")
        
        finally:
            metrics.test_end = datetime.now()
            if metrics.failure_detected and metrics.recovery_completed:
                metrics.total_downtime = (metrics.recovery_completed - metrics.failure_detected).total_seconds()
        
        return metrics
    
    # ==================== COMPARA√á√ÉO E RELAT√ìRIOS ====================
    
    def compare_architectures(self, scenario: str, hybrid: FailureMetrics, traditional: FailureMetrics) -> ComparisonResult:
        """Compara resultados entre arquiteturas"""
        
        # Detec√ß√£o mais r√°pida
        if hybrid.detection_time is not None and traditional.detection_time is not None:
            if hybrid.detection_time < traditional.detection_time:
                faster_detection = 'hybrid'
            elif traditional.detection_time < hybrid.detection_time:
                faster_detection = 'traditional'
            else:
                faster_detection = 'tie'
            detection_diff = abs(hybrid.detection_time - traditional.detection_time)
        else:
            faster_detection = 'unknown'
            detection_diff = None
        
        # Recupera√ß√£o mais r√°pida
        if hybrid.recovery_time is not None and traditional.recovery_time is not None:
            if hybrid.recovery_time < traditional.recovery_time:
                faster_recovery = 'hybrid'
            elif traditional.recovery_time < hybrid.recovery_time:
                faster_recovery = 'traditional'
            else:
                faster_recovery = 'tie'
            recovery_diff = abs(hybrid.recovery_time - traditional.recovery_time)
        else:
            faster_recovery = 'unknown'
            recovery_diff = None
        
        # Menos perda de dados
        if hybrid.loss_percentage < traditional.loss_percentage:
            less_data_loss = 'hybrid'
        elif traditional.loss_percentage < hybrid.loss_percentage:
            less_data_loss = 'traditional'
        else:
            less_data_loss = 'tie'
        
        data_loss_diff = abs(hybrid.loss_percentage - traditional.loss_percentage)
        
        # Melhor disponibilidade
        if hybrid.continued_operating and not traditional.continued_operating:
            better_availability = 'hybrid'
        elif traditional.continued_operating and not hybrid.continued_operating:
            better_availability = 'traditional'
        else:
            better_availability = 'tie'
        
        # Fun√ß√£o auxiliar para formatar valores que podem ser None
        def fmt(value, default='N/A', decimals=2):
            """Formata valor, retorna default se None"""
            if value is None:
                return default
            if isinstance(value, (int, float)):
                return f"{value:.{decimals}f}"
            return str(value)
        
        # Resumo
        summary = f"""
Cen√°rio: {scenario}

Detec√ß√£o de Falha:
  - H√≠brida: {fmt(hybrid.detection_time)}s
  - Tradicional: {fmt(traditional.detection_time)}s
  - Vencedor: {faster_detection} (diferen√ßa: {fmt(detection_diff)}s)

Tempo de Recupera√ß√£o:
  - H√≠brida: {fmt(hybrid.recovery_time)}s
  - Tradicional: {fmt(traditional.recovery_time)}s
  - Vencedor: {faster_recovery} (diferen√ßa: {fmt(recovery_diff)}s)

Perda de Dados:
  - H√≠brida: {fmt(hybrid.loss_percentage)}%
  - Tradicional: {fmt(traditional.loss_percentage)}%
  - Vencedor: {less_data_loss} (diferen√ßa: {fmt(data_loss_diff)}%)

Disponibilidade Durante Falha:
  - H√≠brida: {'Sim' if hybrid.continued_operating else 'N√£o'}
  - Tradicional: {'Sim' if traditional.continued_operating else 'N√£o'}
  - Vencedor: {better_availability}
"""
        
        return ComparisonResult(
            scenario=scenario,
            hybrid=hybrid,
            traditional=traditional,
            faster_detection=faster_detection,
            faster_recovery=faster_recovery,
            less_data_loss=less_data_loss,
            better_availability=better_availability,
            detection_time_diff=detection_diff,
            recovery_time_diff=recovery_diff,
            data_loss_diff=data_loss_diff,
            summary=summary
        )
    
    def generate_report(self, comparisons: List[ComparisonResult], output_file: str):
        """Gera relat√≥rio consolidado"""
        
        report = {
            'test_date': datetime.now().isoformat(),
            'total_scenarios': len(comparisons),
            'comparisons': [],
            'summary': {
                'hybrid_wins': {'detection': 0, 'recovery': 0, 'data_loss': 0, 'availability': 0},
                'traditional_wins': {'detection': 0, 'recovery': 0, 'data_loss': 0, 'availability': 0},
                'ties': {'detection': 0, 'recovery': 0, 'data_loss': 0, 'availability': 0}
            }
        }
        
        for comp in comparisons:
            # Contabilizar vit√≥rias
            for metric in ['detection', 'recovery', 'data_loss', 'availability']:
                winner_attr = f'faster_{metric}' if metric in ['detection', 'recovery'] else f'less_{metric}' if metric == 'data_loss' else f'better_{metric}'
                winner = getattr(comp, winner_attr)
                
                if winner == 'hybrid':
                    report['summary']['hybrid_wins'][metric] += 1
                elif winner == 'traditional':
                    report['summary']['traditional_wins'][metric] += 1
                else:
                    report['summary']['ties'][metric] += 1
            
            report['comparisons'].append({
                'scenario': comp.scenario,
                'hybrid': comp.hybrid.to_dict(),
                'traditional': comp.traditional.to_dict(),
                'winners': {
                    'faster_detection': comp.faster_detection,
                    'faster_recovery': comp.faster_recovery,
                    'less_data_loss': comp.less_data_loss,
                    'better_availability': comp.better_availability
                },
                'differences': {
                    'detection_time': round(comp.detection_time_diff, 2) if comp.detection_time_diff is not None else None,
                    'recovery_time': round(comp.recovery_time_diff, 2) if comp.recovery_time_diff is not None else None,
                    'data_loss': round(comp.data_loss_diff, 2) if comp.data_loss_diff is not None else None
                }
            })
        
        # Salvar JSON
        output_path = RESULTS_DIR / output_file
        with open(output_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"\n‚úÖ Relat√≥rio salvo em: {output_path}")
        
        # Gerar relat√≥rio Markdown
        self.generate_markdown_report(report, output_file.replace('.json', '.md'))
    
    def generate_markdown_report(self, report: Dict, filename: str):
        """Gera relat√≥rio em Markdown"""
        
        output_path = RESULTS_DIR / filename
        
        with open(output_path, 'w') as f:
            f.write("# Relat√≥rio de Testes de Toler√¢ncia a Falhas\n\n")
            f.write(f"**Data do Teste**: {report['test_date']}\n\n")
            f.write(f"**Total de Cen√°rios**: {report['total_scenarios']}\n\n")
            
            f.write("## üìä Resumo Geral\n\n")
            
            summary = report['summary']
            
            f.write("### Vit√≥rias por M√©trica\n\n")
            f.write("| M√©trica | H√≠brida | Tradicional | Empate |\n")
            f.write("|---------|---------|-------------|--------|\n")
            f.write(f"| **Detec√ß√£o de Falha** | {summary['hybrid_wins']['detection']} | {summary['traditional_wins']['detection']} | {summary['ties']['detection']} |\n")
            f.write(f"| **Recupera√ß√£o** | {summary['hybrid_wins']['recovery']} | {summary['traditional_wins']['recovery']} | {summary['ties']['recovery']} |\n")
            f.write(f"| **Perda de Dados** | {summary['hybrid_wins']['data_loss']} | {summary['traditional_wins']['data_loss']} | {summary['ties']['data_loss']} |\n")
            f.write(f"| **Disponibilidade** | {summary['hybrid_wins']['availability']} | {summary['traditional_wins']['availability']} | {summary['ties']['availability']} |\n\n")
            
            # Calcular pontua√ß√£o total
            hybrid_total = sum(summary['hybrid_wins'].values())
            traditional_total = sum(summary['traditional_wins'].values())
            
            f.write(f"### üèÜ Pontua√ß√£o Total\n\n")
            f.write(f"- **H√≠brida**: {hybrid_total} pontos\n")
            f.write(f"- **Tradicional**: {traditional_total} pontos\n\n")
            
            if hybrid_total > traditional_total:
                f.write(f"**Vencedor Geral**: üéØ Arquitetura H√≠brida\n\n")
            elif traditional_total > hybrid_total:
                f.write(f"**Vencedor Geral**: üéØ Arquitetura Tradicional\n\n")
            else:
                f.write(f"**Resultado**: ü§ù Empate T√©cnico\n\n")
            
            # Detalhes por cen√°rio
            f.write("## üîç Detalhes por Cen√°rio\n\n")
            
            for comp in report['comparisons']:
                f.write(f"### {comp['scenario']}\n\n")
                
                f.write("#### Tempos de Resposta\n\n")
                f.write("| M√©trica | H√≠brida | Tradicional | Diferen√ßa | Vencedor |\n")
                f.write("|---------|---------|-------------|-----------|----------|\n")
                
                h_det = comp['hybrid'].get('detection_time', 'N/A')
                t_det = comp['traditional'].get('detection_time', 'N/A')
                f.write(f"| Detec√ß√£o | {h_det}s | {t_det}s | {comp['differences']['detection_time']}s | {comp['winners']['faster_detection']} |\n")
                
                h_rec = comp['hybrid'].get('recovery_time', 'N/A')
                t_rec = comp['traditional'].get('recovery_time', 'N/A')
                f.write(f"| Recupera√ß√£o | {h_rec}s | {t_rec}s | {comp['differences']['recovery_time']}s | {comp['winners']['faster_recovery']} |\n\n")
                
                f.write("#### Integridade de Dados\n\n")
                f.write("| M√©trica | H√≠brida | Tradicional |\n")
                f.write("|---------|---------|-------------|\n")
                f.write(f"| Logs Enviados | {comp['hybrid']['logs_sent_total']} | {comp['traditional']['logs_sent_total']} |\n")
                f.write(f"| Logs Recebidos | {comp['hybrid']['logs_received_total']} | {comp['traditional']['logs_received_total']} |\n")
                f.write(f"| Logs Perdidos | {comp['hybrid']['logs_lost']} | {comp['traditional']['logs_lost']} |\n")
                f.write(f"| % Perda | {comp['hybrid']['loss_percentage']}% | {comp['traditional']['loss_percentage']}% |\n\n")
                
                f.write(f"**Vencedor em Integridade**: {comp['winners']['less_data_loss']}\n\n")
                
                f.write("#### Disponibilidade\n\n")
                f.write(f"- **H√≠brida**: {'‚úÖ Continuou operando' if comp['hybrid']['continued_operating'] else '‚ùå Parou de operar'}\n")
                f.write(f"- **Tradicional**: {'‚úÖ Continuou operando' if comp['traditional']['continued_operating'] else '‚ùå Parou de operar'}\n\n")
                
                f.write("---\n\n")
        
        print(f"‚úÖ Relat√≥rio Markdown salvo em: {output_path}")


# ==================== MAIN ====================

def main():
    """Fun√ß√£o principal"""
    
    print("\n" + "="*70)
    print("  TESTES DE TOLER√ÇNCIA A FALHAS - TCC LOG MANAGEMENT")
    print("="*70)
    print("\nComparando comportamento entre arquiteturas:")
    print("  1. H√≠brida (MongoDB + Hyperledger Fabric)")
    print("  2. Tradicional (PostgreSQL com Streaming Replication)")
    print("\nCen√°rios de teste:")
    print("  ‚Ä¢ Falha do banco de dados principal")
    print("  ‚Ä¢ Falha de n√≥ de replica√ß√£o")
    print("  ‚Ä¢ Falha de rede tempor√°ria")
    print("\nM√©tricas avaliadas:")
    print("  ‚Ä¢ Tempo de detec√ß√£o (RTO)")
    print("  ‚Ä¢ Tempo de recupera√ß√£o (RPO)")
    print("  ‚Ä¢ Integridade dos dados")
    print("  ‚Ä¢ Disponibilidade durante falha")
    print("\n" + "="*70)
    
    input("\nPressione ENTER para iniciar os testes...")
    
    tester = FaultToleranceTest()
    comparisons = []
    
    # CEN√ÅRIO 1: Falha do banco principal
    print("\n\n" + "üî•"*35)
    print("  EXECUTANDO CEN√ÅRIO 1: FALHA DO BANCO PRINCIPAL")
    print("üî•"*35)
    
    hybrid_s1 = tester.test_scenario_1_primary_failure('hybrid')
    time.sleep(5)
    traditional_s1 = tester.test_scenario_1_primary_failure('traditional')
    
    comp1 = tester.compare_architectures('primary_database_failure', hybrid_s1, traditional_s1)
    comparisons.append(comp1)
    
    # CEN√ÅRIO 2: Falha de r√©plica
    print("\n\n" + "üî•"*35)
    print("  EXECUTANDO CEN√ÅRIO 2: FALHA DE R√âPLICA")
    print("üî•"*35)
    
    hybrid_s2 = tester.test_scenario_2_standby_failure('hybrid')
    time.sleep(5)
    traditional_s2 = tester.test_scenario_2_standby_failure('traditional')
    
    comp2 = tester.compare_architectures('replica_node_failure', hybrid_s2, traditional_s2)
    comparisons.append(comp2)
    
    # CEN√ÅRIO 3: Falha de rede
    print("\n\n" + "üî•"*35)
    print("  EXECUTANDO CEN√ÅRIO 3: FALHA DE REDE")
    print("üî•"*35)
    
    hybrid_s3 = tester.test_scenario_3_network_partition('hybrid')
    time.sleep(5)
    traditional_s3 = tester.test_scenario_3_network_partition('traditional')
    
    comp3 = tester.compare_architectures('network_partition', hybrid_s3, traditional_s3)
    comparisons.append(comp3)
    
    # Gerar relat√≥rios
    print("\n\n" + "="*70)
    print("  GERANDO RELAT√ìRIOS")
    print("="*70)
    
    tester.generate_report(comparisons, 'fault_tolerance_report.json')
    
    # Mostrar resumo
    print("\n\n" + "="*70)
    print("  RESUMO DOS RESULTADOS")
    print("="*70)
    
    for comp in comparisons:
        print(comp.summary)
    
    print("\n‚úÖ Testes conclu√≠dos com sucesso!")
    print(f"üìÅ Resultados salvos em: {RESULTS_DIR}/")


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Testes interrompidos pelo usu√°rio")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå Erro durante execu√ß√£o: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
